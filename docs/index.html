<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Tyler Yang, Vincent Wu, CS184-tyang</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>Give a high-level overview of what you implemented in this project. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the project.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
  <p>Triangles are rasterized using the three line test.  Given that a triangle is composed of three intersecting lines, we can check to see whether a point lies within the triangle by checking whether the point’s dot product with the orthogonal vectors of every edge is greater than or equal 0.  The rationale behind this approach is that, if a point lies within the boundary, it’s dot product with the vector orthogonal to the edge should be greater than 0 or equal to 0 (being 0 if the point lies directly on the border).  In the case that that the dot product is negative, it lies outside, the dot product will be negative.  For each point within our sample space, we will sample the point (x,y) at the center of the pixel (x+0.5, y+0.5) and take the color present at this location and store it in the sample buffer calling fill_pixel.  The resolve_to_framebuffer function will then be called, writing in the color at the sample_buffer location into the framebuffer.</p>
  <p>We prove that the sampling is at least as efficient as sampling from the boundary as follows:</p>
  <p style="margin-left: 25px;">Let x<sub>0</sub> = min(x coord of triangle vertices), y<sub>0</sub> = min(y coord of triangle vertices),   x<sub>1</sub> = max(x coord of triangle vertices), y<sub>1</sub> = max(y coord of triangle vertices)
    In order to prevent looping through extraneous points that would not be considered by the triangle, we only sample in the space occupied in the rectangle created from the vertices (x<sub>0</sub>, y<sub>0</sub>),  (x<sub>0</sub>, y<sub>1</sub>),  (x<sub>1</sub>, <sub>0</sub>),  (x<sub>1</sub>, y<sub>1</sub>).  This is, by definition, the bounding box of the triangle and hence is no worse than an algorithm that checks each sample in the bounding box of the triangle.</p>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task1.png" align="middle" width="400px"/>
          <figcaption align="middle">test4.svg with default viewing parameters.</figcaption>
        </td>
      </tr>
    </table>
  </div>
<!--<div align="middle">-->
<!--  <table style="width=100%">-->
<!--    <tr>-->
<!--      <td>-->
<!--        <img src="images/image1.png" align="middle" width="400px"/>-->
<!--        <figcaption align="middle">Caption goes here.</figcaption>-->
<!--      </td>-->
<!--      <td>-->
<!--        <img src="images/image2.png" align="middle" width="400px"/>-->
<!--        <figcaption align="middle">Caption goes here.</figcaption>-->
<!--      </td>-->
<!--    </tr>-->
<!--    <br>-->
<!--    <tr>-->
<!--      <td>-->
<!--        <img src="images/image3.png" align="middle" width="400px"/>-->
<!--        <figcaption align="middle">Caption goes here.</figcaption>-->
<!--      </td>-->
<!--      <td>-->
<!--        <img src="images/image4.png" align="middle" width="400px"/>-->
<!--        <figcaption align="middle">Caption goes here.</figcaption>-->
<!--      </td>-->
<!--    </tr>-->
<!--  </table>-->
<!--</div>-->


<h3 align="middle">Part 2: Antialiasing triangles</h3>
<p>The supersampling algorithm derived works by scaling up our sample buffer to now accommodate space for each of the supersamples that are taken, sampling each supersample associated with that pixel and storing them within the sample buffer, and finally averaging the RGB all of the sample_rate supersamples taken to generate the new pixel to be inserted into the framebuffer.  The largest changes existed within rasterize_triangle.In rasterize_triangle, the inner workings were changed such that for each pixel location (x,y) we traverse in stepsizes of x + 0.5/sqrt(sample_rate) and y + 0.5/sqrt(sample_rate) to acquire a total of sample_rate supersamples to which we will store in the sample buffer.  Simplified steps are presented below:</p>
<ol>
  <li>Scale up sample buffer to now be width * height * sample_rate</li>
  <li>Iterate through each point within the bounding box to see whether a point is within the triangle</li>
  <ol>
    <li>We will now have two more loops with step sizes of 0.5/sqrt(sample_rate) to add incrementally to the x and y values for this pixel</li>
    <li>Each supersample will then be stored in sample buffer at the location <strong>sample_rate * (y * width + x) + index</strong> where sample_rate is the sample rate, x,y being the pixel location, width being the width, and index being the current supersample for this pixel in the range [0, sample_rate - 1]</li>
  </ol>
  <li>
    In resolve_to_framebuffer, we will then call get_avg() to average all of the RGB values across the sample_rate supersamples associated with that pixel to create the new color to be inserted into the frame buffer
  </li>
</ol>
  <p>Supersampling is useful for antialiasing images.  If only one sample is taken per pixel, the result would have “jaggies”, leading to poorly rasterized images.  With supersampling, we are able to eliminate jaggies caused when colors are not directly present in the sampled location but still present within the pixel.  Supersampling allows for one to remove “jaggies” and other artifacts that come from low sample-rate images.</p>
  <p>ince there are now multiple samples associated with the pixel being inserted into the frame buffer,  the rasterization pipeline needed to be modified as there is no longer a 1:1 relationship between the sample buffer and frame buffer.  In resolve_to_framebuffer, instead of writing directly from the sample_buffer into the frame_buffer, we aggregate the associated supersample entries and generate the new color to be entered into the frame buffer.  This entry will have RGB values associated with the average RGB values across all supersample entries.</p>
  <p>Supersampling was used to antialias triangles by averaging the supersampled RGB values.  By rendering a higher resolution image, we are able to get more information about the image which can then be used when downsampling the image.  By having more information we can represent the color values of pixels more easily and remove artifacts such as jaggies.</p>
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task2_1.png" align="middle" width="300px"/>
        <figcaption align="middle">sample rate = 1</figcaption>
      </td>
      <td>
        <img src="images/task2_4.png" align="middle" width="300px"/>
        <figcaption align="middle">sample rate = 4</figcaption>
      </td>
      <td>
        <img src="images/task2_16.png" align="middle" width="300px"/>
        <figcaption align="middle">sample rate = 16</figcaption>
      </td>
    </tr>
  </table>
  <p>The results are observed due to the location of the edge within the pixel.  With a sample rate of 1, if the edge does not reach the point being sampled, it will not show up in the image.  This leads to the jaggie pattern seen in the first image.  As we increase the sampling rate, we are able to get more information as to the location of the edges within the triangle and therefore able to more accurately color the pixels.  As the sampling rate increases, we are able to generate more accurate representations due to more sampling points per pixel.</p>
<h3 align="middle">Part 3: Transforms</h3>
<p>With my new transformations, I was attempting to recreate Usain Bolt’s iconic victory pose after winning several gold medals in olympic events in the 100m and 200m.  To do so, I had to rotate his arm into the proper positions to create the iconic stance as well as making him kneel by bending and rotating his legs.</p>
  <div align="middle">
        <img src="images/usain_bolt.png" align="middle" width="300px"/>
        <figcaption align="middle">Usain Bolt in iconic stance using transformations in robot.svg</figcaption>
  </table>
  </div>


<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>



<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
